---
title: "7. praktikum"
knit: (function(input_file, encoding) {
    out_dir <- 'docs';
    rmarkdown::render(input_file,
      encoding=encoding,
      output_file=file.path(dirname(input_file), out_dir, '7-valim_hypoteesid.html'))})
date: 11.03.2024
output: 
  html_document:
    theme: flatly
    highlight: tango
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Valim ja populatsioon. Hüpoteesid ja tõenäosus. {.tabset .tabset-pills}

## Tänases praktikumis

**Tänased teemad:**  

- Valim ja populatsioon  
- Kirjeldav ja järeldav statistika  
- Hüpoteesid ja tõenäosus  
- Jaotused: normaaljaotus  
- Hüpoteeside testimine: parameetrilised testid  


Lisaks varem kasutatud küsimustikule kasutame üllatusküsimuste andmestikku.

```{r}
load("data/kysimustik_2024.RData")
load("data/yllatuskysimused_koneleja_keskmised.Rda")
```


## Üllatusküsimuste andmestik

Andmed on pärit üllatus- ja infoküsimuste prosoodilise markeerimise uurimusest. Uurimuse eesmärk oli uurida, kuidas kõnes tähistatakse üllatust. Infoküsimused on kannoonilised küsilaused, mille eesmärk on küsida infot. Üllatusküsimuste esmane eesmärk on väljendada imestust või üllatust. Katse tulemused on avaldatud artiklis

Asu, Eva Liina, Heete Sahkai & Pärtel Lippus. 2024. The prosody of surprise questions in Estonian. Journal of Linguistics 60(1). 7–27. https://doi.org/10.1017/S0022226723000014.

Katse viidi läbi nii, et katseisikutele näidati kõigepealt ekraanil lühikest olukorrakirjeldust ja seejärel paluti lugeda kõva häälega küsimus nii, nagu see sobiks kirjeldatud situatsiooni.

```{r, echo=F, message=F}
library(tidyverse)
library(flextable)
data.frame(`Infokontekst` = c("Saad sõbra juures head veini. Tahad teada, mis vein see on, et seda järgmisel korral külalistele pakkuda.", "Su kolleeg on kutsutud ühte gümnaasiumisse ettekannet pidama. Sa tahad teada, mis teemal ta ettekande teeb."),
           `Üllatuskontekst` = c("Sa tuled koos abikaasaga poest ja leiad poekotist punase veini. Sa oled üllatunud, sest sinu mäletamist mööda ostsite te hoopis valge veini.", "Su sõber jääb kohtumisele pool tundi hiljaks. Kui ta lõpuks kohale jõuab, hakkab ta sinu üllatuseks ja pahameeleks vabandamise asemel hoopis sind süüdistama."),
           Küsimus = c("Mis vein see on?", "Mida sa räägid?")) %>%     flextable() %>% 
    set_table_properties( layout = "autofit") %>% 
    set_caption(caption = "Näide kontekstidest ja küsimustest.")
```

Stiimulitena varieeriti 12 erinevat *mis*-küsimust ja 12 *mida*-küsimust. *Mis*-küsimused olid kõik struktuuriga *Mis NOOMEN see on?* ning *mida*-küsimused *Mida sa VERB?*. Kõik küsimused esitati kord info- ja kord üllatuskontekstis. Seega 2 x 2 x 12 = 48 stiimulit. Katseisikuid oli kokku 21 (kõik naised), seega kokku 1008 on andmestikus 1008 esitatud küsimust. Kõva häälega loetud küsimused salvestati ja mõõdeti lausungi kestust ja põhitooni.


### Täisandmestikust koondandmestik

**Seda kõike siin ei pea läbi tegema**, kui sul on Moodlist võimalik alla laadida koondandmestik valmis kujul (fail `yllatuskysimused_koneleja_keskmised.Rda`). Kui ei või kui tahad proovida kõik sammud järjest läbi, siis kogu andmestik on vabalt allalaetav [Open Science Framework'i repositooriumist](https://osf.io/knygh/). Sealt tuleks alla laadida fail `Est_SQ-ISQ_dataset_JLing.Rda`.

```{r, eval = F}
load("data/Est_SQ-ISQ_dataset_JLing.Rda")
```

Sellisel kujul tuleme selle andmestiku juurde tagasi mõne nädala pärast, kui teeme tutvust segamudelitega. Kuna esialgu kasutame statistikuid, mis eeldavad sõltumatuid mõõtmisi (sellest räägime järgmises praktikumis), siis teisendame andmed sellisele kujule, et meil oleks igalt katseisikult üks keskmistatud mõõtmine iga katse konditsiooni kohta. Võtame suurest andmestikust kaasa:

- lausungi kestuse
- põhitooni keskmine 
- põhitooni ulatus
- põhitooni kõrgus lausungi alguses
- põhitooni kõrgus lausungi lõpus

Kestus on mõõdetud sekundites, põhitoon hertsides ning teisendatud ka pooltoonideks kõneleja keskmise põhitooni kõrguse suhtes.

```{r, eval=F}
dat %>% 
    group_by(sp, tyyp1, kysisona) %>% 
    summarise(kestus = mean(phr_dur), 
              f0_kesk_Hz = mean(phr_f0_mean), 
              f0_ulat_Hz = mean(phr_f0_q95-phr_f0_q05),
              f0_alg_Hz = mean(phr_f0_start, na.rm=T), 
              f0_lopp_Hz = mean(phr_f0_stop, na.rm=T), 
              f0_kesk_sem = mean(phr_sem_mean, na.rm = T),
              f0_ulat_sem = mean(phr_sem_q95-phr_sem_q05),
              f0_alg_sem = mean(phr_sem_start, na.rm=T),
              f0_lopp_sem = mean(phr_sem_stop, na.rm=T)) -> ylla
save(ylla, file = "data/yllatuskysimused_koneleja_keskmised.Rda")
```


## Valim ja populatsioon

**Populatsiooni** ehk **üldkogumi** moodustavad uurimisobjekti kõik esindajad. Enamasti on populatsioon nii suur ja raskesti kättesaadav, et ei ole võimalik uurida kogu populatsiooni. Näiteks kui uurime inimkäitumist, siis populatsioon on kogu inimkond, kui uurime eesti keelt, siis kõik eesti keele kõnelejad ja kõik, mis nad iganes räägivad, või kõik eesti keeles kirjutatud tekstid. Sõltuvalt uurimisküsimustest võib muidugi ka populatsioon olla hoomatavam: näiteks kui uurime Anton Hansen Tammsaare loomingut, siis kogu populatsiooni moodustavad kõik tema teosed.

**Valim** on mingite kriteeriumite alusel tehtud valik uurimisobjektidest, mis uuringus vaatluse alla võetakse ja mille omadusi kogu populatsioonile laiendatakse.

**Kõikne uuring**: mõõdetakse kogu populatsiooni ehk kõik objektid üldkogumis (nt rahvaloendus, aga ka nt kõik ühe kirjaniku teosed).

- **Üldkogum** ehk **populatsioon**: objektide hulk, kelle/mille kohta soovitakse järeldusi teha.
- Plussid:
    + täpne info.
- Miinused:
    + töömahukas,
    + kallis,
    + mahukuse tõttu võivad kumuleeruda vead,
    + piiratud sisu.


**Valikuuring**: vaadeldakse osa (valimit) üldkogumi objektidest, järeldus terviku kohta tehakse selle osa põhjal.

- **Valim**: osa üldkogumist, mida uuritakse/mõõdetakse.
- Plussid:
    + väiksem maksumus,
    + suurem kiirus,
    + operatiivsus (saab korraldada vastavalt vajadustele),
    + suurem täpsus.
- Miinused:
    + jääb sisse juhuslik viga, mis on tingitud valimi juhuslikkusest.


## Valimi moodustamine

Valimi põhjal saadud tulemused peaksid olema võimalikult lähedased neile, mida võiksime saada kogu üldkogumit mõõtes.

- Näiteks kui uurida leibkondade elujärge, peavad olema valimisse kaasatud kõik leibkonnatüübid.

Valimi suuruse määrab ülesanne, mida tahetakse lahendada.
 
**Lihtne juhuvalim**: igal üldkogumi objektil on võrdne tõenäosus sattuda valimisse.

- Parim variant, aga võib olla liiga töömahukas.

**Kihtvalim**: üldkogum jagatakse mingi tunnuse alusel kihtideks, igas kihis rakendadakse mingit valikumeetodit (nt juhuvalikut). Valim vastab selle valitud tunnuse alusel üldkogumis valitsevale proportsioonile.

**Esindusvalim**: valim koostatakse nii, et erinevate võimalike tunnuste proportsioonid on võrdsed.

- Näiteks inimese pikkust uurides võetakse valimisse sama arv mehi ja naisi, noortest vanadeni, igast uuritava üldkogumi piirkonnast jne;
- lihtsam kui juhuvalik;
- on oht, et mingid olulised tunnused jäävad arvestamata.

**Mugavusvalim**: valimisse kaasatakse need objektid, mida on lihtne küsitleda/mõõta.

- Kõige halvem variant;
- kõige kergemini saadav;
- mõnikord ainuke võimalik variant.
- Näiteks õppejõud kutsub oma tajukatsesse tema kursusel käivad üliõpilased.

## Hüpoteeside testimine

### Kirjeldav vs. järeldav statistika

**Kirjeldavas** andmeanalüüsis kasutatakse meetodeid valimi kirjeldamiseks ja näitlikustamiseks. Kirjeldava statistikana võib valimi kohta välja tuua näiteks keskmised väärtused või andmetes esinenud väärtuste sagedused.<br>
**Järeldavas (tõestavas)** andmeanalüüsis on meetodid, mis kasutavad valimist saadud tulemusi üldkogumi kohta käivate otsuste ja prognooside tegemiseks. Enamasti kasutatakse tõenäosuslikke teste, et hinnata valimi kuulumist mingisse populatsiooni.

Sageli ei ole uurija huvitatud keskmise taseme arvulisest väärtusest, vaid pigem sellest, kas üldkogumi keskväärtus rahuldab mingit teatud tingimust.

### Statistiline hüpotees

Selleks tuleb sõnastada statistiline hüpotees.

- Väide: naised ja mehed on tööturul ebavõrdses olukorras.
- Statistiline hüpotees: naiste ja meeste keskmine palk ei ole võrdne.
<br>
<br>
- Väide: mahlapakkides ei ole nii palju mahla kui lubatud.
- Statistiline hüpotees: keskmine mahla kogus pakendis erineb lubatust.


Statistiline hüpotees esitatakse alati hüpoteeside paarina.

- keskmine mahla kogus pakis = 1 liiter (nullhüpotees)
- keskmine mahla kogus pakis ≠ 1 liiter (sisukas/alternatiivne hüpotees)
<br>
<br>
- naiste keskmine palk = meeste keskmine palk
- naiste keskmine palk ≠ meeste keskmine palk

Need hüpoteesid on üksteist välistavad, st alati peab üks neist kehtima ja korraga saab kehtida ainult üks.

### Nullhüpotees H0 ja sisukas hüpotees H1

Nullhüpotees väidab tavaliselt üldkogumi vastavust teatud standardile. See on väide üldkogumi parameetri kohta ja kehtib nii kaua, kuni seda pole ümber lükatud. Parameeter tähendab siinjuures mingit populatsiooni iseloomustavad näitajat (nt Eesti meeste keskmine pikkus), mille väärtust me sageli ei tea.

**Nullhüpoteesi ei saa tõestada!** (vähemalt ilma kogu populatsiooni mõõtmata)

Sisukas hüpotees on väide üldkogumi parameetri kohta, mis on tõene siis, kui nullhüpotees osutub valeks.

H0: väide, mida eeldatakse üldkogumis kehtivat<br>
H1: tõestamist vajav hüpotees


## Tõenäosus hüpoteeside vastuvõtmisel ja vead

Uurime enamasti populatsiooni, ent mõõdame üldjuhul valimit. Mingi parameetri hinnang valimis on **statistik**. Statistikameetodite abil ei saa väiteid tõestada absoluutselt kindlasti, alati jääb teatav eksimise võimalus ja juhuslikkusest tulenev eksimus.

```{r, echo=FALSE}
library(knitr)
tab = matrix(c("I tüüpi viga",  "Kõik hästi", "Kõik hästi", "II tüüpi viga"), ncol=2, byrow=T)
rownames(tab) <- c("Lükkad H0 tagasi", "Võtad H0 vastu")
colnames(tab) <- c("H0 on tõene", "H0 on vale")
kable(tab)
```

*p*-väärtus ehk **olulisuse tõenäosus** on see, mida statistilistes testides otsuse langetamiseks kasutatakse. Olulisuse tõenäosus on eksimise risk nullhüpoteesi kummutamisel ja sisuka hüpoteesi vastuvõtmisel. Tõenäosust hindame skaalal 0 -- 1.

*α* (alfa) ehk **olulisuse nivoo** on maksimaalne lubatud eksimise tõenäosus sisuka hüpoteesi tõestamisel. Maksimaalse vea valib otsustaja, tavaline on **_α_ = 0,05**, mis tähendab, et tõenäosus eksida on väiksem kui 5%, mis pööratuna lubab väita rohkem kui 95% kindlusega, et sisukas hüpotees kehtib. Olenevalt andmetest ja testist võib _α_ aga olla ka 0.1 või 0.001.

Kui kohtleme p-väärtust liiga leebelt ja seame _α_ liiga suureks, siis on oht teha I tüüpi viga ja kuulutada oluliseks efekte, mis tegelikult on juhuslik varieerumine. Kui kohtleme liiga rangelt ja seame _α_ liiga väikseks, siis on oht magada maha olulisi erinevusi ja pidada neid juhuslikuks vareerumiseks.

Alternatiivne definitsioon: olulisuse tõenäosus on tõenäosus, et nullhüpoteesi korral saab saadud tulemuse juhuslikult.

Reegel:

- kui *p* < *α*, siis on tõestatud sisukas hüpotees H1;
- kui *p* > *α*, siis jäädakse nullhüpoteesi juurde, pole võimalik midagi muud tõestada.

### Näide

Näiteks _kujutame ette_, et uurime, kas _eesti keele sõnade keskmine pikkus erineb ingliskeelsete sõnade pikkusest_ (sest nt eesti keeles on ju rohkem morfoloogiat, ulatuslik sõnamoodustussüsteem jne). Nullhüpotees oleks sel juhul, et mingit erinevust kahe keele sõnade pikkuses ei ole, ning sisukas hüpotees, et erinevus on olemas (ega ole juhuslik).  

Võtame selle teadasaamiseks mõlema keele tekstikorpustest välja kõikide nendes esinevate unikaalsete sõnavormide nimekirjad ning leiame kummagi keele kohta sõnade keskmise pikkuse (tähemärkides). Oletame, et lepiksime sellega, kui 5-s juhuslikus valimis 100st (antud juhul sõnade nimekirjade paaris) oleks eesti- ja ingliskeelsete sõnade keskmise pikkuse erinevus oluliselt teistugune kui meie nimekirjade põhjal, aga samas 95-s valimis oleks see meie omale sarnane. *α* on seega 0,05.  

Kui nüüd kahe grupi keskmisi võrdleva testi *p*-väärtus oleks 0,03, siis tõenäosus, et saame nii suure (= nullist erineva) statistiku väärtuse JA ikkagi kehtib nullhüpotees (= seost ei ole / seos on juhuslik), on 3%. Kuna *p* < *α*, võtame vastu sisuka ehk alternatiivse hüpoteesi selle kohta, et eestikeelsete ja ingliskeelsete sõnade pikkused on keskmiselt erinevad, ning hülgame nullhüpoteesi, mille kohaselt kahe keele sõnade keskmised pikkused on samasugused.

## Ühe- ja kahepoolsed hüpoteesid

**Kahepoolne hüpotees**: kui tahame näidata seda, et keskmine on erinev mingist konstandist (nt populatsiooni keskmine) või ühe rühma keskmine on erinev teise rühma keskmisest.

- H0: keskmine = a VÕI keskmine1 = keskmine2
- H1: keskmine ≠ a VÕI keskmine1 ≠ keskmine2

Kui aga teooriast on teada, milline see erinevus peaks olema, siis saab kontrollida **ühepoolset hüpoteesi**. Sellisel juhul kontrollime seda, kas rühma keskmine on suurem kui populatsiooni keskmine. Või kahe rühma korral kas ühe rühma keskmine on suurem teise rühma keskmisest.

- H0: keskmine >= a VÕI keskmine1 >= keskmine2
- H1: keskmine < a VÕI keskmine1 < keskmine2


### Näiteid: t-test (keskmiste võrdlemine)

T-testist tuleb põhjalikumalt juttu järgmises praktikumis. See on test, millega võrrelda kahe rühma arvulise tunnuse keskmisi väärtusi, test näitab, kui tõenäone on, et vaadeldavad rühmad on samast populatsioonist juhuslikult võetud valimit. 

Üllatusküsimuste andmestikus vaatasime lausungi kestust ja leidsime, et nagu mitmetes teistes keeltes, on eesti keeles üllatusküsimused (*surprise question*, SQ) pikemad kui infoküsimused (*information-seeking question*, ISQ). 

Seame hüpoteesid kahepoolsetena:

- H0: ISQ = SQ (kahe rühma kestused on võrdsed)
- H1: ISQ ≠ SQ (kahe rühma kestused ei ole võrdsed)

```{r}
t.test(kestus ~ tyyp1, data = ylla, var.equal = T, alternative = "two.sided")
```

Kuna meil on varasemast teada teiste keelte kohta, et üllatusküsimused on pikema kestusega kui infoküsimused, võiksime sõnastada hüpoteesid ühepoolsetena:

- H0: ISQ >= SQ (esimese rühma keskmine on suurem või võrdne teisega)
- H1: ISQ < SQ (esimese rühma keskmine on väiksem kui teisel)

Teeme t-testi, kus alternatiivhüpotees on, et esimese rühma keskmine on väiksem kui teise rühma oma:

```{r}
t.test(kestus ~ tyyp1, data = ylla, var.equal = T, alternative = "less")
```

Nii saame poole väiksema p-väärtuse, mistõttu see tundub ju parem. Siin peab aga arvestama, et kahepoolne hüpotees peaks loogiliselt olema välistatud, ning peab hoolega jälgima, kumba poolt hüpoteesist testime. Sest näiteks kui sama andmestiku peal teha t-testi teist pidi ühepoolsete hüpoteesidega, siis saame tulemuseks, et olulist erinevust rühmade vahel ei ole:

- H0: ISQ <= SQ
- H1: ISQ > SQ (infoküsimused on pikema kestusega kui üllatusküsimused)

```{r}
t.test(kestus ~ tyyp1, data = ylla, var.equal = T, alternative = "greater")
```


```{r}
ggplot(data = ylla) +
  geom_boxplot(aes(x = tyyp1, y = kestus)) +
  labs(y = "Lausungi kestus (sek)", x = "Küsimuse tüüp")
```

## Paar näidet ühe- ja kahepoolsetest hüpoteesidest

Meil on küsimustikule vastanute seas nii kohvi- kui teejoojaid. Testime, kas nad kuuluvad samasse üliõpilaste populatsiooni näiteks õppimisaja poolest. Hüpoteesid on järgnevad:


H0: kohvijoojate õppimisaeg = teejoojate õppimisaeg<br>
H1: kohvijoojate õppimisaeg ≠ teejoojate õppimisaeg

Kas need hüpoteesid on ühe- või kahepoolsed?

```{r}
t.test(kaua_opid ~ lemmikjook, data = kysimustik, var.equal = T)
```
  
Vaatame esialgu lihtsalt *p*-väärtust, mis on `r round(t.test(kaua_opid ~ lemmikjook, data = kysimustik, var.equal = T)$p.value, 3)`. Nagu kiri testis ütleb, siis on alternatiivne hüpotees ehk H1 see, et keskmiste erinevus populatsioonis ei ole 0. Kuna vaikimisi on *α* väärtus enamasti 0.05 ja seega *p* > *α*, siis me alternatiivset hüpoteesi vastu võtta ei saa ja peame jääma nullhüpoteesi juurde, mille kohaselt kohvijoojate õppimisaeg ei erine teejoojate õppimisajast.

Sama näeme ka karpdiagrammilt.  


```{r}
ggplot(data = kysimustik) +
  geom_boxplot(aes(x = lemmikjook, y = kaua_opid)) +
  labs(y = "Ülikoolis õppimise aeg (aastates)", x = "Lemmikjook")
```


Teine näide: kas üliõpilased, kellel on varasemaid kogemusi kvantitatiivsete meetoditega, on keskmiselt kauem ülikoolis õppinud kui need, kellel kogemusi ei ole?

H0: kogemuseTA õppimisaeg = kogemuseGA õppimisaeg<br>
H1: kogemuseTA õppimisaeg < kogemuseGA õppimisaeg


```{r,results = 'hold'}
t.test(kaua_opid ~ kogemused_kvant, data = kysimustik, alternative = "less", var.equal=T)
boxplot(kaua_opid ~ kogemused_kvant, data = kysimustik)
```

NB! Ühepoolse hüpoteesi testimiseks peaksime me eelnevalt konkreetsest valimist sõltumatult teadma, et kvantitatiivsete meetodite kogemustega üliõpilased ei saa olla vähem aega ülikoolis õppinud kui ilma kogemusteta üliõpilased, sest ühepoolse testiga me seda võimalust üldse ei testi.
Peale selle peab ühepoolse testi puhul `y~x` süntaksit kasutades teadma, mis on faktori `x` tasemed. Argument **`alternative = "less"`** tähendab, et järjekorras 1. tase ehk baastase < alternatiivtase. Vaatame igaks juhuks üle, mis on tasemete järjekord:
```{r}
levels(kysimustik$kogemused_kvant)
```

```{r, echo=F}
test.p.vaartus <- (t.test(kaua_opid ~ kogemused_kvant, data = kysimustik, alternative = "less", var.equal=T)$p.value)
```

Kuna "Ei" on baastase, võrdleb test argumendiga `alternative = "less"` seda, kas "Ei" grupis ehk kvantmeetodite kogemuseTA üliõpilaste seas oleks keskmine õpinguaeg **lühem** kui "Jah" grupis.
Kuna *p*-väärtus on `r test.p.vaartus`, siis saame vastu võtta alternatiivse ehk sisuka hüpoteesi ning tõdeda, et kvantmeetodite kogemuseta üliõpilaste ülikoolis õpitud aeg on keskmiselt lühem kui kogemustega üliõpilastel.

Kui seame oma hüpoteesid valesti, siis ühepoolse testiga võime teha valesid järeldusi:
```{r}
t.test(kaua_opid ~ kogemused_kvant, data = kysimustik, alternative = "greater", var.equal=T)
```
Sellise ühepoolse testi tulemus, et **ILMA kogemusteta** rühma õppimiseg **ei ole pikem** kui **kogemustega** rühmal, ei tähenda automaatselt, et rühmad ei ole erinevad ja et nad kuuluvad samasse populatsiooni, sest kogemusteTA rühma õppimisaeg võib ka olla lühem kui kogemusteGA rühmal. Seega, kui meil ei ole kindlat põhjust kasutada ühepoolset testi, siis peaks alati valima pigem kahepoolse.

## Jaotused, normaaljaotus

Jaotus (ingl *distribution*) näitab seda, kuidas andmepunktid on skaalal jaotatud.

```{r, echo=FALSE, fig.align = 'center', fig.height = 8, fig.width = 12}
par(mfrow=c(2,3))
plot(function(x)dunif(x, min=-3, max=3), -3,3, main="Ühtlane jaotus")
plot(function(x)dnorm(x), -3,3, main="Normaaljaotus")
plot(function(x)df(x,3,100), 0,4, main="Asümmeetriline")
plot(function(x)df(x,1,10)/3, 0.2,3, main="J-jaotus")
plot(function(x)(dnorm(x, mean=3, sd=1)+dnorm(x, mean=-3, sd=1))/2, -6,6, main="Kahetipuline jaotus")
plot(function(x)-dnorm(x), -3,3, main="U-jaotus")
```
Joonise kood Keith Johnson 2008, Quantitative methods in linguistics, lk 14-15.

 - **ühtlase jaotuse** puhul on kõiki väärtuseid võrdne hulk;
 - **normaaljaotuse** kõige sagedasem väärtus on keskmine ja väärtused jagunevad selle ümber ühtlaselt mõlemale poole;
- **asümmeetrilise jaotuse** tipp ehk sagedaseim väärtus ei ole keskmine ja tipust allapoole ja ülespoole jäävad servad ei ole sümmeetrilised;
- **J-jaotuse** puhul on kõige sagedasem väärtus ühes skaala otsas ja väärtuste sagedus langeb skaala teise otsa poole liikudes;
- **Kahetipulises jaotuses** on kaks sagedasemat väärtust;

### Normaaljaotus

Normaaljaotus e Gaussi jaotus iseloomustab tunnust, mille puhul suur hulk väärtusi koonduvad keskmise ümber, keskmisest oluliselt erinevaid väärtusi on vähe ning need jaotuvad keskmisest ühtlaselt mõlemale poole. Vt Galtoni seemnesorteerija, mis genereerib normaaljaotusega hunnikuid: <https://en.wikipedia.org/wiki/Bean_machine>

**Miks normaaljaotus nii hea on?**

- Langevad kokku keskmine ja mediaan.
- Keskmisest ühe standardhälbe kaugusel on 68% vaatlustest, kahe standardhälbe kaugusel 95% vaatlustest ja kolme standardhälbe kaugusel 99% vaatlustest.

```{r, echo=FALSE}
par(mfcol=c(1,1))
plot(function(x)dnorm(x), -3,3, main="Normaaljaotus", xlab = "Standardhälve", ylab = "(Suhteline) sagedus", ylim=c(-0.02, 0.5))
polygon(x=c(-3,3,3,-3), y=c(0,0,0.05,0.05), border = F, col=rainbow(1, start = 0.6, alpha=0.2))
text(x=0, y=0.015, "3 sd 99% andmetest", col="black")
arrows(y0=0, y1=0, x0=-3, x1=3,code = 3)
polygon(x=c(-2,2,2,-2), y=c(0,0,0.24,0.24), border = F,col=rainbow(1, start = 0.4, alpha=0.2))
text(x=0, 0.065, "2 sd 95% andmetest", col="black")
arrows(y0=0.05, y1=0.05, x0=-2, x1=2,code = 3)
polygon(x=c(-1,1,1,-1), y=c(0,0,0.4,0.4), border = F, col=rainbow(1, start=0.2, alpha=0.2))
text(x=0, 0.28, "1 sd\n68% andmetest", col="black")
arrows(y0=0.24, y1=0.24, x0=-1, x1=1,code = 3)
```

**...järelikult on see kirjeldatav kahe arvuga**

Kui me teame teame **keskmist** ja **standardhälvet**, siis me võime tuletada kõigi teiste punktide väärtused.
<br><br>
Näiteks kui meil on (hüpoteetiliselt) klassitäis lapsi (ütleme nt 32 last), kelle keskmine pikkus on 150 cm ja standardhälve on 10 cm, 

- siis on üsna tõenäone, et nad jäävad vahemikku 120-180 cm (st 3 standardhälvet kummalegi poole keskmist) 
- ja tõenäoselt mitte rohkem kui 5 last on lühemad kui 140 cm ja mitte rohkem kui 5 last pikemad kui 160 cm (68% jäävad ±1 standardhälbe piiresse, seega 100-68=32% jäävad sellest välja, sellest pooled ehk 16% jäävad sellest allapoole ning sama palju sellest ülespoole, 32-st 16% on 5.12).

Näiteks: genereerime vektori 32 väärtusega, mis on normaaljaotusega, keskmine 1.5 ja standardhälve 0.1
```{r}
pikkus <- rnorm(n=32, mean=1.5, sd=0.1)
summary(pikkus)
```
```{r}
sd(pikkus)
```
NB! Kuna rnorm() genereerib väärtused juhuslikult, siis on tulemus iga kord erinev!

```{r, fig.align = 'center'}
hist(pikkus)
```

Juhuslik valim ei pruugi alati ideaalselt normaaljaotusega olla. Näiteks kui korrata seda käsku 10 korda, siis tulemus on iga kord veidi erinev ja mitte alati päris sümmeetriline: 
```{r, fig.align = 'center', fig.height = 6, fig.width = 12}
par(mfrow=c(2,5))
for(i in 1:10) hist(rnorm(32 ,1.5, 0.1), xlim=c(1.2, 1.8), breaks = 10)
```


Aga mida suurem valim, seda rohkem läheneb normaaljaotusele. Genereerime mitu eri suurusega valimit samast jaotusest:
```{r, fig.align = 'center', fig.height = 6, fig.width = 12}
par(mfrow=c(2,5))
for(i in 1:10) hist(rnorm(2^i ,1.5, 0.1), xlim=c(1.2, 1.8), main=paste(2^i, "punkti"))
par(mfrow=c(1,1))
```



## Normaaljaotuse testimine


Kuna paljud statistilised testid (t-test, anova, lineaarne regressioon) eeldavad, et andmed on normaaljaotusega, siis peaks enne testi kasutamist veenduma, et eeldus on täidetud.
<br><br>
Jaotuse normaalsuse testimiseks on võimalik:

- vaadata histogrammi ja visuaalselt hinnata (`hist()`)
- võrrelda tegelikku ja teoreetilist kvantiilide jaotust (`qqnorm()` ja `qqline()`)
- kasutada normaaljaotuse testi (Shapiro-Wilk, Anderson-Darling või Kolmogorovi–Smirnovi test)

### Histogramm

Histogrammi vaadates näeb (enam-vähem), kas jaotus on sümmeetriline. See ei ole mingi lollikindel test, aga annab esmase ülevaate.
```{r}
hist(pikkus)
```
```{r}
# ggplotiga
ggplot(data = as.data.frame(pikkus)) +
  geom_histogram(aes(x = pikkus), bins = 9)
```


### Kvantiilide võrdlemine

Üks võimalus on võrrelda andmete kvantiiljaotust. Kas teoreetiline ja tegelik jaotus lähevad kokku?
```{r}
qqnorm(pikkus)
qqline(pikkus)
```
```{r}
# ggplotiga
ggplot(data = as.data.frame(pikkus), 
       aes(sample = pikkus)) +
  geom_qq() +
  geom_qq_line()
```


### Shapiro-Wilki test

Shapiro testi **nullhüpotees** on, et valim **on** pärit **normaaljaotusega** populatsioonist. Tulemus on *p*-väärtus, mis on tõenäosuslik hinnang, et nullhüpotees kehtib. Kuna **pikkus** on juhuslikult genereeritud, siis on väärtused iga kord erinevad, aga näiteks kui *p* = `r shapiro.test(pikkus)$p`, siis võib öelda, et `r round(shapiro.test(pikkus)$p*100)`% tõenäosusega on tegu normaaljaotusega. Tulemuse tõlgendamisel on tavaliselt *α* = 0.05 ehk et kui on *p* > 0.05, võib otsustada, et on normaaljaotus, kui on *p* < 0.05, siis ei ole. 

```{r}
shapiro.test(pikkus)
```

Tasub tähele panna, et *p*-väärtuse tõlgendamine selles testis käib seega mõnes mõttes teistpidi kui teistes testides, millega järgmistel kordadel tegeleme, kui tahame näha võimalikult väikseid p-väärtusi. *p*-väärtuse tõlgendamine tuleneb otseselt nullhüpoteesist.

### Anderson-Darling

Anderson-Darlingi test on Shapiro-Wilki testile sarnane, aga väidetavasti natuke leebem.

```{r}
# install.packages('nortest')
library(nortest)

ad.test(pikkus)
```


## Normaaljaotuse testimine (1. näide)

Me juba kasutasime t-testi, et võrrelda info- ja üllatusküsimuste kestust. T-test aga on parameetriline test, mis eeldab andmetelt normaaljaotust (sellest lähemalt järgmisel korral). Seega peaksime enne testi kasutamist veenduma, et kestus on normaaljaotusega.



### Histogramm

Kas jaotus on sümmeetriline?

```{r, eval=T}
hist(ylla$kestus)
```

Normaaljaotuse puhul peaks kõige kõrgem tulp jääma joonise keskele ning tulpade kõrgus kahanema enam-vähem ühtlaselt mõlema skaala äärmuse suunas. Sellel joonisel tundub, et ülemine ots on natuke välja venitatud ja võib-olla ei ole tegemist ideaalse normaalaotusega. 

### Kvantiilide võrdlemine

Üks võimalus on võrrelda andmete kvantiiljaotust. Kas teoreetiline ja tegelik jaotus lähevad kokku?
```{r, eval=T}
ggplot(data = ylla, 
       aes(sample = kestus)) +
  geom_qq() +
  geom_qq_line()
```

Vasakul, y-teljel näeme tegelikke kvantiile, x-teljel teoreetilisi kvantiile (väärtused standardhälvetes). Seega -1 ja 1 standardhälbe vahemikus, kuhu peaks jääma 66.7% andmetest, on teotreetiliste ja tegelike andmete jaotus üsna sarnane, aga mõlemal pool otstes lähevad jaotused lahku. Tegelik jaotus on küll enam-vähem sümmeetriline, aga natuke paremale välja venitatud.


### Milline võiks jaotus välja näha, kui andmed oleksid normaaljaotusega?

Saame genereerida teoreetilised väärtused keskmise ja standardhälbe põhjal.

```{r}
# Tegelike andmete keskmine
(kesk <- mean(ylla$kestus))
# Tegelike andmete standardhälve
(shalve <- sd(ylla$kestus))
```

```{r}
# Tegelikud väärtused, mis hõlmavad 99%, 95% ja 68% andmetest
quantile(ylla$kestus, probs = c(0.005, 0.025, 0.16, 0.5, 0.84, 0.975, 0.995))
# Kolm, kaks ja üks standardhälvet keskmisest
round(c(kesk-3:1*shalve, kesk, kesk+1:3*shalve),3)
```

Siin kõrvuti tegelik jaotus (must joon) ja teoreetiline normaaljaotus samade mõõtmistearvu, keskmise ja standardhälbe korral (punane joon):

```{r, echo=F}
set.seed(1)
plot(density(rnorm(n = length(ylla$kestus), 
             mean = mean(ylla$kestus), 
             sd = sd(ylla$kestus))), col="red",     main = "Tegelik vs. teoreetiline normaaljaotus")
lines(density(ylla$kestus),
 xlim=c(kesk-3*shalve, max(ylla$kestus)))
```


### Normaalajotuse testid

Shapiro-Wilki test hindab *tõenäosust, et valim on pärit normaaljaotusega populatsioonist*. Testi nullhüpotees on, et valim **on** pärit normaaljaotusega populatsioonist. Tulemuse tõlgendamisel on tavaliselt *α* = 0.05 ehk kui *p* > 0.05, võib otsustada, et on normaaljaotus (me ei saa nullhüpoteesi ümber lükata), kui *p* < 0.05, siis ei ole (on alust vastu võtta alternatiivne hüpotees: valim ei ole pärit normaaljaotusega populatsioonist). 

```{r, eval=F}
shapiro.test(ylla$kestus)
```

Nagu ka joonistelt juba näha oli, ei ole lausungite kestused normaaljaotusega: *p*-väärtus on `r shapiro.test(ylla$kestus)$p.value` ehk on `r round(shapiro.test(ylla$kestus)$p.value*100, 1)`-protsendiline tõenäosus, et saaksime sama suure (enamasti see tähendab lihtsalt, et nullist erineva) statistiku väärtuse juhul, kui nullhüpotees ikkagi kehtib. See on väga väike tõenäosus, seega hülgame nullhüpoteesi.

Võib ka proovida Anderson-Darlingi testi, mis on natuke leebem ja piiripealsetel juhtudel võime sellega saada oodatuma tulemuse.

```{r}
nortest::ad.test(ylla$kestus)
```

Ja tõepoolest, testi tulemus ütleb, et on `r round(nortest::ad.test(ylla$kestus)$p.value*100, 1)`% tõenäosus, et tegemist on normaaljaotusega, mis lubab jääda 0-hüpoteesi juurde ja väita, et tegemist on normaaljaotusega.

### Kui ei ole normaalajaotus, mis siis saab?

- Ürita andmeid normaliseerida VÕI
- kasuta mitteparameetrilist testi.

Enamasti, kui  andmed on paremale kallutatud (*right-skewed*) ehk väikeseid väärtusi on rohkem kui suuri ning mood ja mediaan on seega väiksemad kui aritmeetiline keskmine (mida tuleb ette tihti, kui mõõdame millegi kestust, pikkust vms suurust), siis võib jaotuse normaliseerida see, kui andmed logaritmida. Logaritmimine on astendamise pöördtehe ehk kui astendades leiame mingi väärtuse $a^b=c$, siis logaritmides leiame hoopis astendaja $log_{a}c=b$. Näiteks $2^3=8$ (ehk `2*2*2=8`)ja $log_28=3$. Mingeid väärtusi logaritmides teisendame need seega mingi kokkulepitud väärtuse (nt *`e`*, 10, 2 vm) astendajateks ning vähendame seeläbi suurte erinevuste mõju väärtuste vahel.

```{r}
# Võtame nt 2 arvu: 10 ja 100.
# Teine on esimesest 10 korda suurem.
100/10

# Kui mõlemat logaritmida,
# on erinevus ainult kahekordne.
log(100)/log(10)
```

Logaritmimiseks on R-is niisiis käsk `log()`, mis vaikimisi kasutab kokkulepitud väärtuse ehk alusena (valemis $a$) Euleri arvu *`e`*, mis on `2.71828`. Võib kasutada ka funktsiooni `log2()`, mille alus on 2, `log10()`, mille alus on 10, või kui andmetes on väärtus 0, siis `log1p()`. Viimane liidab igale väärtusele 1 juurde. Seda seepärast, et logaritm mis tahes alusel arvust 0 on negatiivne lõpmatus, millega pole midagi pihta hakata. **Logaritmida saab ainult positiivseid arve!**

```{r}
log(0)
```

Ja teisipidi, kui andmed oleks vasakule kaldu, saaks kasutada logaritmimise pöördtehet ehk astendamist, milleks on R-is käsk `exp()`.


Vaatame nüüd lausungite kestuste logaritmitud väärtuste jaotust. Kui kestuse mediaanväärtus on `r median(ylla$kestus)`, siis selle logaritm oleks `r log(median(ylla$kestus))`, sest `2.71828^``r log(median(ylla$kestus))` on `r 2.71828^log(median(ylla$kestus))`.  

```{r, eval=F}
hist(log(ylla$kestus))

qqnorm(log(ylla$kestus))
qqline(log(ylla$kestus))

shapiro.test(log(ylla$kestus))
```

Kas logaritmimine aitas meil saavutada uuritava tunnuse normaaljaotuse?

 - kui *p* > 0.05, siis jääme nullhüpoteesi juurde, mille kohaselt andmed on normaaljaotusega.
 - Kui *p* < 0.05, lükkame nullhüpoteesi ümber ja järeldame, et andmed **ei ole normaaljaotusega**.


Tegelik vs. teoreetiline normaaljaotus logaritmitud andmetega:

```{r, echo=F}
set.seed(1)
plot(density(rnorm(n = length(ylla$kestus), 
             mean = mean(log(ylla$kestus)), 
             sd = sd(log(ylla$kestus)))), col="red", main = "Tegelik vs. teoreetiline normaaljaotus")
lines(density(log(ylla$kestus)))
```



Aga peale selle, et üritada andmeid normaliseerida, tasuks kontrollida, palju andmeid oligi.  Parameetriliste testide puhul peaks normaaljaotuse nõudesse rangemalt suhtuma juhul, kui mõõtmisi on vähem kui 30. Kui mõõtmisi on alla 30 ja andmed ei ole normaaljaotusega ka normaliseerides, siis peaks valima mitteparameetrilise testi. Kui andmeid on rohkem, siis võib ka mitte normaaljaotusega andmestikuga parameetrilist testi teha.


## Normaaljaotuse testimine (2. näide)

Oletame, et tahame vaadata, kas ülikoolis õpitud aastate arv erineb nende hulgas, kel on kvantitatiivsete meetoditega varasemaid kogemusi, ja nende hulgas, kellel ei ole. Uuritav tunnus on arvuline ja seletav/grupeeriv kategoriaalne, seega on esimesed kaks eeldust täidetud. Samuti on täidetud valimi juhuslikkuse nõue. Testime nüüd normaaljaotust.  

### Histogramm

Kas jaotus on sümmeetriline?

```{r, eval=T}
hist(kysimustik$kaua_opid)
```

Normaaljaotuse puhul peaks kõige kõrgem tulp jääma joonise keskele ning tulpade kõrgus kahanema enam-vähem ühtlaselt mõlema skaala äärmuse suunas. Sellel joonisel ei ole seega väga tõenäoliselt tegu normaaljaotusega. 

### Kvantiilide võrdlemine

Üks võimalus on võrrelda andmete kvantiiljaotust. Kas teoreetiline ja tegelik jaotus lähevad kokku?
```{r, eval=T}
library(ggplot2)
ggplot(data = kysimustik, 
       aes(sample = kaua_opid)) +
  geom_qq() +
  geom_qq_line()
```

Vasakul, y-teljel näeme tegelikke kvantiile: ehkki mõõtmiste skaala on `r min(kysimustik$kaua_opid)` -- `r max(kysimustik$kaua_opid)` aastat, jääb suurem osa andmepunkte `r paste(quantile(kysimustik$kaua_opid, probs = c(0.25,0.75)), collapse =" ja ")` vahele. Sellise jagunemise puhul eeldaks normaaljaotus (qq-joonel), et 95% andmetest jääks keskmisest +-2 standarhälbe kaugusele (x-teljel) ehk et andmepunktide skaala ulatus oleks antud juhul ülemisest otsast palju väiksem ning ulatuks alumises otsas palju kaugemale (miinuspoolele).


### Milline võiks jaotus välja näha, kui andmed oleksid normaaljaotusega?

Saame genereerida teoreetilised väärtused keskmise ja standardhälbe põhjal.

```{r}
# Tegelike andmete keskmine
(kesk <- mean(kysimustik$kaua_opid))
# Tegelike andmete standardhälve
(shalve <- sd(kysimustik$kaua_opid))
```

```{r}
# Tegelikud väärtused, mis hõlmavad 99%, 95% ja 68% andmetest
quantile(kysimustik$kaua_opid, probs = c(0.005, 0.025, 0.16, 0.5, 0.84, 0.975, 0.995))
# Kolm, kaks ja üks standardhälvet keskmisest
round(c(kesk-3:1*shalve, kesk, kesk+1:3*shalve),3)
```

Siin kõrvuti tegelik jaotus (must joon) ja teoreetiline normaaljaotus õppimisaja mõõtmistearvu, keskmise ja standardhälbe korral (punane joon):

```{r, echo=F}
plot(density(kysimustik$kaua_opid),
     main = "Tegelik vs. teoreetiline normaaljaotus", xlim=c(kesk-3*shalve, max(kysimustik$kaua_opid)))
set.seed(1)
lines(density(rnorm(n = length(kysimustik$kaua_opid), 
             mean = mean(kysimustik$kaua_opid), 
             sd = sd(kysimustik$kaua_opid))), col="red")
```


### Shapiro-Wilki test

Shapiro-Wilki test hindab *tõenäosust, et valim on pärit normaaljaotusega populatsioonist*. Testi nullhüpotees on, et valim **on** pärit normaaljaotusega populatsioonist. Tulemuse tõlgendamisel on tavaliselt *α* = 0.05 ehk kui *p* > 0.05, võib otsustada, et on normaaljaotus (me ei saa nullhüpoteesi ümber lükata), kui *p* < 0.05, siis ei ole (on alust vastu võtta alternatiivne hüpotees: valim ei ole pärit normaaljaotusega populatsioonist). 

```{r, eval=F}
shapiro.test(kysimustik$kaua_opid)
```

Nagu ka joonistelt juba näha oli, ei ole ülikoolis käidud aastate arv normaaljaotusega: *p*-väärtus on `r shapiro.test(kysimustik$kaua_opid)$p.value` ehk on `r shapiro.test(kysimustik$kaua_opid)$p.value*100`-protsendiline tõenäosus, et saaksime sama suure (enamasti see tähendab lihtsalt, et nullist erineva) statistiku väärtuse juhul, kui nullhüpotees ikkagi kehtib. See on väga väike tõenäosus, seega hülgame nullhüpoteesi.

### Kas on võimalik normaliseerida?

Kuna meil on andmed jälle paremale kallutatud (*right-skewed*) ehk väikeseid väärtusi on rohkem kui suuri ning mood ja mediaan on seega väiksemad kui aritmeetiline keskmine, siis võib jaotuse normaliseerida see, kui andmed logaritmida. 

```{r, eval=F}
hist(log(kysimustik$kaua_opid))

qqnorm(log(kysimustik$kaua_opid))
qqline(log(kysimustik$kaua_opid))

shapiro.test(log(kysimustik$kaua_opid))
```

Kas logaritmimine aitas meil saavutada uuritava tunnuse normaaljaotuse?

 - kui *p* > 0.05, siis jääme nullhüpoteesi juurde, mille kohaselt andmed on normaaljaotusega.
 - Kui *p* < 0.05, lükkame nullhüpoteesi ümber ja järeldame, et andmed **ei ole normaaljaotusega**.


Tegelik vs. teoreetiline normaaljaotus logaritmitud andmetega:

```{r, echo=F}
set.seed(1)
plot(density(rnorm(n = length(kysimustik$kaua_opid), 
             mean = mean(log(kysimustik$kaua_opid)), 
             sd = sd(log(kysimustik$kaua_opid)))), col="red", main = "Tegelik vs. teoreetiline normaaljaotus")
lines(density(log(kysimustik$kaua_opid)))
```


Aga peale selle, et üritada andmeid normaliseerida, tasuks kontrollida, palju andmeid oligi.  Parameetriliste testide puhul peaks normaaljaotuse nõudesse rangemalt suhtuma juhul, kui mõõtmisi on vähem kui 30. Kui mõõtmisi on alla 30 ja andmed ei ole normaaljaotusega ka normaliseerides, siis peaks valima mitteparameetrilise testi. Kui andmeid on rohkem, siis võib ka mitte normaaljaotusega andmestikuga parameetrilist testi teha.

```{r}
length(kysimustik$kaua_opid)
```

## Lõpetuseks

### Harjutusi

Proovi `kysimustik` ja `ylla` andmestike peal:

- Millistelt tunnustelt võiks üldse normaaljaotust eeldada?
- Vaata nende tunnuste histogrammi, qq-graafikut ja tee Shapiro test.
- Kas andmed on normaaljaotusega?
- Kui ei, kas logaritmimisega on võimalik normaliseerida?


### Järgmisel korral


Gruppidevaheliste erinevuste hindamine (arvuline sõltuv tunnus ~ kategoriaalne seletav tunnus):  

- parameetrilised testid (kui eeldused on täidetud)
  * t-test (kaks rühma)
- mida teha, kui ei ole normaaljaotus? (logaritmimine)
- mitteparameetrilised testid (kui pole normaaljaotus)
  * Wilcoxoni test (kaks rühma)
  
  
## Funktsioonide sõnastik

- `rnorm(n, mean, sd)` - genereerib n-pikkuse vektori juhuslikest normaaljaotusega arvudest, millel on ette antud keskmine ja standardhälbe väärtus
- `hist()` - joonistab histogrammi
- `qqnorm()` ja `qqline()` kvantiiljaotuse joonis
- `shapiro.test()` - Shapiro-Wilki test
- `nortest::ad.test()` - Anderson-Dralingi test

- `log()` - naturaallogaritm
- `log1p()` - liidab enne logaritmimist väärtustele ühe (kui andmetes on 0-väärtusi)
- `exp()` - astendamine, logaritmimise pöördtehe
- `t.test()` - t-testi käsk, sellest rohkem järgmine kord